import torch
import numpy as np
from PIL import Image
import os
import time
import json
import hashlib
import folder_paths
from typing import List, Dict, Tuple, Optional

# yicheng author
class YCImageAccumulator:
    """
    å›¾åƒç´¯ç§¯å±•ç¤ºèŠ‚ç‚¹ - ç´¯ç§¯ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒï¼Œæ”¯æŒé€‰æ‹©è¾“å‡º
    
    åŠŸèƒ½ç‰¹ç‚¹ï¼š
    1. ç´¯ç§¯æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„å›¾åƒï¼ˆä¸ä¼šè¢«æ¸…é™¤ï¼‰
    2. æ”¯æŒä»ç´¯ç§¯çš„å›¾åƒä¸­é€‰æ‹©ä»»æ„ä¸€å¼ è¾“å‡º
    3. æ”¯æŒä¸åŒå°ºå¯¸/æ¯”ä¾‹çš„å›¾åƒ
    4. ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼šå®Œæ•´å›¾åƒä¿å­˜åˆ°æ–‡ä»¶ï¼Œå†…å­˜ä¸­åªä¿ç•™å…ƒæ•°æ®
    5. è‡ªåŠ¨é™åˆ¶æœ€å¤§æ•°é‡ï¼Œé˜²æ­¢æ— é™ç´¯ç§¯
    """
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€"""
        # å›¾åƒå…ƒæ•°æ®åˆ—è¡¨ï¼ˆå†…å­˜ä¸­åªä¿å­˜å…ƒæ•°æ®ï¼Œä¸ä¿å­˜å®Œæ•´å›¾åƒï¼‰
        self.image_metadata: List[Dict] = []
        
        # ç´¯ç§¯å›¾åƒçš„ä¿å­˜ç›®å½•ï¼ˆä½¿ç”¨ComfyUIä¸´æ—¶ç›®å½•çš„å­ç›®å½•ï¼‰
        temp_dir = folder_paths.get_temp_directory()
        self.gallery_dir = os.path.join(temp_dir, "image_accumulator")
        os.makedirs(self.gallery_dir, exist_ok=True)
        
        # å½“å‰ä¼šè¯IDï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„ç´¯ç§¯ä¼šè¯ï¼‰
        self.session_id = self._generate_session_id()
        
    def _generate_session_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID"""
        timestamp = str(time.time())
        return hashlib.md5(timestamp.encode()).hexdigest()[:8]
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "è¦ç´¯ç§¯çš„è¾“å…¥å›¾åƒ"}),
                "selected_index": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 999,
                    "step": 1,
                    "tooltip": "é€‰æ‹©è¦è¾“å‡ºçš„å›¾åƒç´¢å¼•ã€‚-1è¡¨ç¤ºæœ€æ–°å›¾åƒï¼Œ0è¡¨ç¤ºç¬¬ä¸€å¼ "
                }),
            },
            "optional": {
                "clear_gallery": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ¸…ç©ºæ‰€æœ‰ç´¯ç§¯çš„å›¾åƒ"
                }),
                "max_images": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 100,
                    "step": 1,
                    "tooltip": "æœ€å¤§ç´¯ç§¯å›¾åƒæ•°é‡ï¼Œè¶…è¿‡åä¼šæ›¿æ¢æŒ‡å®šä½ç½®çš„å›¾åƒ"
                }),
                "update_position": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 99,
                    "step": 1,
                    "tooltip": "è¾¾åˆ°ä¸Šé™åï¼Œæ–°å›¾åƒæ›¿æ¢çš„ä½ç½®ã€‚-1=æœ€åä¸€å¼ ï¼Œ0=ç¬¬1å¼ ï¼Œ1=ç¬¬2å¼ ..."
                }),
                "batch_start": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 99,
                    "step": 1,
                    "tooltip": "æ‰¹æ¬¡è¾“å‡ºèµ·å§‹ç´¢å¼•ã€‚-1=å•å¼ è¾“å‡ºï¼ˆä½¿ç”¨selected_indexï¼‰ï¼Œ0å¼€å§‹=æ‰¹æ¬¡è¾“å‡º"
                }),
                "batch_end": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 99,
                    "step": 1,
                    "tooltip": "æ‰¹æ¬¡è¾“å‡ºç»“æŸç´¢å¼•ã€‚ä¾‹å¦‚ï¼šstart=0,end=2è¾“å‡º3å¼ (0,1,2)"
                }),
                "align_mode": (["first", "largest", "smallest"], {
                    "default": "largest",
                    "tooltip": "æ‰¹æ¬¡å¯¹é½æ¨¡å¼ï¼šfirst=ç¬¬ä¸€å¼ å°ºå¯¸ï¼Œlargest=æœ€å¤§å°ºå¯¸ï¼Œsmallest=æœ€å°å°ºå¯¸"
                }),
                "pad_color": ("STRING", {
                    "default": "#000000",
                    "tooltip": "æ‰©å›¾å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼Œå¦‚ #000000=é»‘è‰², #FFFFFF=ç™½è‰², #808080=ç°è‰²ï¼‰"
                }),
                "save_to_output": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦å°†ç´¯ç§¯çš„å›¾åƒä¹Ÿä¿å­˜åˆ°outputç›®å½•ï¼ˆæŒä¹…åŒ–ï¼‰"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("images", "masks")
    OUTPUT_NODE = True  # æ ‡è®°ä¸ºè¾“å‡ºèŠ‚ç‚¹ï¼Œä»¥ä¾¿åœ¨UIä¸­æ˜¾ç¤ºå›¾åƒ
    FUNCTION = "accumulate_and_select"
    CATEGORY = "YCNode/Image"
    DESCRIPTION = "ç´¯ç§¯ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„å›¾åƒï¼Œæ”¯æŒå•å¼ æˆ–æ‰¹æ¬¡è¾“å‡ºã€‚é€‚åˆå¯¹æ¯”å¤šæ¬¡ç”Ÿæˆçš„ç»“æœã€‚"
    
    def accumulate_and_select(
        self, 
        image: torch.Tensor, 
        selected_index: int = -1,
        clear_gallery: bool = False,
        max_images: int = 30,
        update_position: int = -1,
        batch_start: int = -1,
        batch_end: int = -1,
        align_mode: str = "largest",
        pad_color: str = "#000000",
        save_to_output: bool = False
    ) -> Dict:
        """
        ä¸»å¤„ç†å‡½æ•°ï¼šç´¯ç§¯å›¾åƒå¹¶é€‰æ‹©è¾“å‡º
        
        Args:
            image: è¾“å…¥çš„å›¾åƒå¼ é‡ [B, H, W, C]
            selected_index: å•å¼ è¾“å‡ºçš„å›¾åƒç´¢å¼•ï¼ˆ-1è¡¨ç¤ºæœ€æ–°ï¼‰
            clear_gallery: æ˜¯å¦æ¸…ç©ºå›¾åƒåº“
            max_images: æœ€å¤§ç´¯ç§¯æ•°é‡
            update_position: è¾¾åˆ°ä¸Šé™åæ›¿æ¢çš„ä½ç½®ï¼ˆ-1è¡¨ç¤ºæœ€åä¸€å¼ ï¼‰
            batch_start: æ‰¹æ¬¡è¾“å‡ºèµ·å§‹ç´¢å¼•ï¼ˆ-1è¡¨ç¤ºå•å¼ è¾“å‡ºï¼‰
            batch_end: æ‰¹æ¬¡è¾“å‡ºç»“æŸç´¢å¼•
            align_mode: æ‰¹æ¬¡å¯¹é½æ¨¡å¼ï¼ˆfirst/largest/smallestï¼‰
            pad_color: æ‰©å›¾å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼‰
            save_to_output: æ˜¯å¦ä¿å­˜åˆ°outputç›®å½•
            
        Returns:
            åŒ…å«UIä¿¡æ¯å’Œè¾“å‡ºç»“æœçš„å­—å…¸
        """
        # 1. æ¸…ç©ºå›¾åƒåº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if clear_gallery:
            self._clear_gallery()
            # é‡æ–°ç”Ÿæˆä¼šè¯ID
            self.session_id = self._generate_session_id()
        
        # 2. å¤„ç†è¾“å…¥å›¾åƒï¼ˆå¯èƒ½æ˜¯batchï¼‰
        batch_size = image.shape[0]
        for i in range(batch_size):
            single_image = image[i:i+1]  # ä¿æŒ4ç»´ [1, H, W, C]
            self._save_image_to_gallery(single_image, save_to_output, max_images, update_position)
        
        # 3. å‡†å¤‡UIå±•ç¤ºæ•°æ®
        ui_images = self._prepare_ui_images()
        
        # 4. åˆ¤æ–­è¾“å‡ºæ¨¡å¼ï¼šå•å¼  or æ‰¹æ¬¡
        if batch_start == -1:
            # å•å¼ è¾“å‡ºæ¨¡å¼
            output_images, output_masks = self._select_single_image(selected_index)
        else:
            # æ‰¹æ¬¡è¾“å‡ºæ¨¡å¼
            output_images, output_masks = self._select_batch_images(batch_start, batch_end, align_mode, pad_color)
        
        # 5. è¿”å›ç»“æœ
        return {
            "ui": {
                "images": ui_images  # å‰ç«¯æ˜¾ç¤ºæ‰€æœ‰å›¾åƒ
            },
            "result": (output_images, output_masks)
        }
    
    def _save_image_to_gallery(self, image: torch.Tensor, save_to_output: bool = False, max_images: int = 30, update_position: int = -1):
        """
        ä¿å­˜å•å¼ å›¾åƒåˆ°å›¾åƒåº“
        
        æ”¹è¿›é€»è¾‘ï¼š
        - å¦‚æœæœªè¾¾åˆ°ä¸Šé™ï¼šæ­£å¸¸æ·»åŠ æ–°å›¾åƒ
        - å¦‚æœè¾¾åˆ°ä¸Šé™ï¼šæ›¿æ¢æŒ‡å®šä½ç½®çš„å›¾åƒï¼ˆé»˜è®¤æœ€åä¸€å¼ ï¼‰
        
        Args:
            image: å›¾åƒå¼ é‡ [1, H, W, C]
            save_to_output: æ˜¯å¦åŒæ—¶ä¿å­˜åˆ°outputç›®å½•
            max_images: æœ€å¤§å›¾åƒæ•°é‡
            update_position: è¾¾åˆ°ä¸Šé™åæ›¿æ¢çš„ä½ç½®ï¼ˆ-1=æœ€åä¸€å¼ ï¼Œ0=ç¬¬1å¼ ï¼Œ1=ç¬¬2å¼ ...ï¼‰
        """
        # è·å–å›¾åƒä¿¡æ¯
        height, width = image.shape[1], image.shape[2]
        timestamp = time.time()
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ä¸Šé™
        is_full = len(self.image_metadata) >= max_images
        
        if is_full:
            # è¾¾åˆ°ä¸Šé™ï¼šç¡®å®šè¦æ›¿æ¢çš„ä½ç½®
            if update_position == -1:
                # æ›¿æ¢æœ€åä¸€å¼ ï¼ˆé»˜è®¤ï¼‰
                replace_index = len(self.image_metadata) - 1
                position_desc = "æœ€åä¸€å¼ "
            elif 0 <= update_position < len(self.image_metadata):
                # æ›¿æ¢æŒ‡å®šä½ç½®
                replace_index = update_position
                position_desc = f"ç¬¬{update_position + 1}å¼ "
            else:
                # è¶…å‡ºèŒƒå›´ï¼Œå›é€€åˆ°æœ€åä¸€å¼ 
                replace_index = len(self.image_metadata) - 1
                position_desc = "æœ€åä¸€å¼ "
                print(f"[ImageAccumulator] âš ï¸  update_position={update_position} è¶…å‡ºèŒƒå›´(0~{len(self.image_metadata)-1})ï¼Œä½¿ç”¨æœ€åä¸€å¼ ")
            
            print(f"[ImageAccumulator] ğŸ“¦ å›¾åƒåº“å·²æ»¡({max_images}å¼ )ï¼Œæ›¿æ¢{position_desc}(ç´¢å¼•{replace_index})")
            
            # åˆ é™¤è¦æ›¿æ¢ä½ç½®çš„å›¾åƒæ–‡ä»¶
            old_metadata = self.image_metadata[replace_index]
            if os.path.exists(old_metadata["temp_path"]):
                try:
                    os.remove(old_metadata["temp_path"])
                except Exception as e:
                    print(f"[ImageAccumulator] åˆ é™¤æ—§æ–‡ä»¶å¤±è´¥: {e}")
            
            # ä½¿ç”¨ç›¸åŒçš„ç´¢å¼•ï¼ˆä¿æŒç´¢å¼•è¿ç»­æ€§ï¼‰
            index = old_metadata["index"]
            
            # ç”Ÿæˆæ–°æ–‡ä»¶åï¼ˆä½¿ç”¨ç›¸åŒç´¢å¼•ï¼‰
            filename = f"{self.session_id}_{index:03d}_{width}x{height}.png"
            
            # ä¿å­˜æ–°å›¾åƒåˆ°ä¸´æ—¶ç›®å½•
            temp_filepath = os.path.join(self.gallery_dir, filename)
            self._save_tensor_to_file(image, temp_filepath)
            
            # å¯é€‰ï¼šä¿å­˜åˆ°outputç›®å½•
            output_filepath = None
            if save_to_output:
                output_dir = folder_paths.get_output_directory()
                output_subdir = os.path.join(output_dir, "image_accumulator", self.session_id)
                os.makedirs(output_subdir, exist_ok=True)
                output_filepath = os.path.join(output_subdir, filename)
                self._save_tensor_to_file(image, output_filepath)
            
            # æ›´æ–°æŒ‡å®šä½ç½®çš„å…ƒæ•°æ®
            self.image_metadata[replace_index] = {
                "index": index,
                "filename": filename,
                "temp_path": temp_filepath,
                "output_path": output_filepath,
                "width": width,
                "height": height,
                "aspect_ratio": round(width / height, 2),
                "timestamp": timestamp,
                "time_str": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp)),
                "size_kb": os.path.getsize(temp_filepath) / 1024 if os.path.exists(temp_filepath) else 0
            }
            
            print(f"[ImageAccumulator] â™»ï¸  å·²æ›´æ–°{position_desc} #{index}: {width}x{height} @ {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))}")
            
        else:
            # æœªè¾¾åˆ°ä¸Šé™ï¼šæ­£å¸¸æ·»åŠ æ–°å›¾åƒ
            index = len(self.image_metadata)
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = f"{self.session_id}_{index:03d}_{width}x{height}.png"
            
            # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼ˆç”¨äºUIæ˜¾ç¤ºå’Œåç»­è¯»å–ï¼‰
            temp_filepath = os.path.join(self.gallery_dir, filename)
            self._save_tensor_to_file(image, temp_filepath)
            
            # å¯é€‰ï¼šåŒæ—¶ä¿å­˜åˆ°outputç›®å½•ï¼ˆæŒä¹…åŒ–ï¼‰
            output_filepath = None
            if save_to_output:
                output_dir = folder_paths.get_output_directory()
                output_subdir = os.path.join(output_dir, "image_accumulator", self.session_id)
                os.makedirs(output_subdir, exist_ok=True)
                output_filepath = os.path.join(output_subdir, filename)
                self._save_tensor_to_file(image, output_filepath)
            
            # æ·»åŠ æ–°çš„å…ƒæ•°æ®
            metadata = {
                "index": index,
                "filename": filename,
                "temp_path": temp_filepath,
                "output_path": output_filepath,
                "width": width,
                "height": height,
                "aspect_ratio": round(width / height, 2),
                "timestamp": timestamp,
                "time_str": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(timestamp)),
                "size_kb": os.path.getsize(temp_filepath) / 1024 if os.path.exists(temp_filepath) else 0
            }
            
            self.image_metadata.append(metadata)
            
            print(f"[ImageAccumulator] â• å·²ç´¯ç§¯å›¾åƒ #{index}: {width}x{height} @ {metadata['time_str']}")
    
    def _save_tensor_to_file(self, image: torch.Tensor, filepath: str):
        """
        å°†å›¾åƒå¼ é‡ä¿å­˜ä¸ºPNGæ–‡ä»¶
        
        Args:
            image: å›¾åƒå¼ é‡ [1, H, W, C]ï¼Œå€¼èŒƒå›´ [0, 1]
            filepath: ä¿å­˜è·¯å¾„
        """
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        i = 255.0 * image[0].cpu().numpy()
        img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
        
        # ä¿å­˜ä¸ºPNG
        img.save(filepath, compress_level=4)
    
    def _limit_gallery_size(self, max_images: int):
        """
        é™åˆ¶å›¾åƒåº“å¤§å°ï¼ˆå·²åºŸå¼ƒï¼Œé€»è¾‘ç§»è‡³_save_image_to_galleryï¼‰
        
        æ–°é€»è¾‘ï¼š
        - åœ¨ä¿å­˜å›¾åƒæ—¶å°±åˆ¤æ–­æ˜¯å¦è¾¾åˆ°ä¸Šé™
        - è¾¾åˆ°ä¸Šé™æ—¶æ›¿æ¢æœ€åä¸€å¼ ï¼Œè€Œä¸æ˜¯åˆ é™¤æœ€æ—§çš„
        - è¿™æ ·å¯ä»¥ä¿æŒå‰é¢çš„å†å²è®°å½•ä¸å˜
        
        Args:
            max_images: æœ€å¤§å›¾åƒæ•°é‡
        """
        # è¿™ä¸ªå‡½æ•°ç°åœ¨ä¸éœ€è¦åšä»»ä½•äº‹æƒ…
        # æ‰€æœ‰é€»è¾‘å·²ç»åœ¨ _save_image_to_gallery ä¸­å¤„ç†
        pass
    
    def _prepare_ui_images(self) -> List[Dict]:
        """
        å‡†å¤‡UIå±•ç¤ºçš„å›¾åƒåˆ—è¡¨
        
        Returns:
            UIå›¾åƒä¿¡æ¯åˆ—è¡¨
        """
        ui_images = []
        
        for metadata in self.image_metadata:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if os.path.exists(metadata["temp_path"]):
                ui_images.append({
                    "filename": metadata["filename"],
                    "subfolder": "image_accumulator",  # ç›¸å¯¹äºtempç›®å½•çš„å­æ–‡ä»¶å¤¹
                    "type": "temp",
                    # é¢å¤–ä¿¡æ¯ï¼ˆå¯åœ¨å‰ç«¯ä½¿ç”¨ï¼‰
                    "index": metadata["index"],
                    "width": metadata["width"],
                    "height": metadata["height"],
                })
        
        return ui_images
    
    def _select_single_image(self, selected_index: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        é€‰æ‹©å•å¼ å›¾åƒè¾“å‡º
        
        Args:
            selected_index: å›¾åƒç´¢å¼•ï¼ˆ-1è¡¨ç¤ºæœ€æ–°ï¼‰
            
        Returns:
            (å›¾åƒå¼ é‡ [1, H, W, C], é®ç½©å¼ é‡ [1, H, W])
        """
        # æ£€æŸ¥å›¾åƒåº“æ˜¯å¦ä¸ºç©º
        if len(self.image_metadata) == 0:
            print("[ImageAccumulator] âš ï¸  å›¾åƒåº“ä¸ºç©ºï¼Œè¿”å›ç©ºå›¾åƒ")
            empty_image = torch.zeros((1, 64, 64, 3), dtype=torch.float32)
            empty_mask = torch.ones((1, 64, 64), dtype=torch.float32)  # å…¨ç™½é®ç½©
            return empty_image, empty_mask
        
        # å¤„ç†ç´¢å¼•
        if selected_index == -1:
            selected_index = len(self.image_metadata) - 1  # æœ€æ–°å›¾åƒ
        else:
            # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
            selected_index = max(0, min(selected_index, len(self.image_metadata) - 1))
        
        # è·å–å…ƒæ•°æ®
        metadata = self.image_metadata[selected_index]
        
        # ä»æ–‡ä»¶è¯»å–å›¾åƒ
        try:
            image = self._load_image_from_file(metadata["temp_path"])
            
            # å•å¼ å›¾åƒæ²¡æœ‰å¡«å……ï¼Œåˆ›å»ºå…¨ç™½é®ç½©ï¼ˆè¡¨ç¤ºå…¨éƒ¨æ˜¯åŸå§‹å›¾åƒï¼‰
            h, w = image.shape[1], image.shape[2]
            mask = torch.ones((1, h, w), dtype=torch.float32)
            
            print(f"[ImageAccumulator] ğŸ“¤ è¾“å‡ºå•å¼ å›¾åƒ #{metadata['index']}: {metadata['width']}x{metadata['height']}")
            return image, mask
            
        except Exception as e:
            print(f"[ImageAccumulator] âŒ åŠ è½½å›¾åƒå¤±è´¥: {e}")
            empty_image = torch.zeros((1, 64, 64, 3), dtype=torch.float32)
            empty_mask = torch.ones((1, 64, 64), dtype=torch.float32)
            return empty_image, empty_mask
    
    def _select_batch_images(self, batch_start: int, batch_end: int, align_mode: str, pad_color: str) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        é€‰æ‹©æ‰¹æ¬¡å›¾åƒè¾“å‡ºï¼ˆæ™ºèƒ½å¯¹é½ï¼‰
        
        Args:
            batch_start: èµ·å§‹ç´¢å¼•
            batch_end: ç»“æŸç´¢å¼•
            align_mode: å¯¹é½æ¨¡å¼ï¼ˆfirst/largest/smallestï¼‰
            pad_color: å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼‰
            
        Returns:
            (æ‰¹æ¬¡å›¾åƒå¼ é‡ [N, H, W, C], æ‰¹æ¬¡é®ç½©å¼ é‡ [N, H, W])
        """
        # æ£€æŸ¥å›¾åƒåº“æ˜¯å¦ä¸ºç©º
        if len(self.image_metadata) == 0:
            print("[ImageAccumulator] âš ï¸  å›¾åƒåº“ä¸ºç©ºï¼Œè¿”å›ç©ºå›¾åƒ")
            empty_image = torch.zeros((1, 64, 64, 3), dtype=torch.float32)
            empty_mask = torch.ones((1, 64, 64), dtype=torch.float32)
            return empty_image, empty_mask
        
        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        batch_start = max(0, min(batch_start, len(self.image_metadata) - 1))
        batch_end = max(0, min(batch_end, len(self.image_metadata) - 1))
        
        # ç¡®ä¿ start <= end
        if batch_start > batch_end:
            batch_start, batch_end = batch_end, batch_start
        
        # è·å–æ‰¹æ¬¡ç´¢å¼•èŒƒå›´
        indices = list(range(batch_start, batch_end + 1))
        
        print(f"[ImageAccumulator] ğŸ“¦ æ‰¹æ¬¡è¾“å‡º: ç´¢å¼• {batch_start}-{batch_end} ({len(indices)}å¼ )")
        
        # åŠ è½½æ‰€æœ‰å›¾åƒ
        images = []
        for idx in indices:
            if idx < len(self.image_metadata):
                metadata = self.image_metadata[idx]
                try:
                    img = self._load_image_from_file(metadata["temp_path"])
                    images.append(img)
                except Exception as e:
                    print(f"[ImageAccumulator] âš ï¸  åŠ è½½å›¾åƒ#{idx}å¤±è´¥: {e}")
        
        if not images:
            print("[ImageAccumulator] âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾åƒ")
            empty_image = torch.zeros((1, 64, 64, 3), dtype=torch.float32)
            empty_mask = torch.ones((1, 64, 64), dtype=torch.float32)
            return empty_image, empty_mask
        
        # ç¡®å®šç›®æ ‡å°ºå¯¸
        target_height, target_width = self._get_target_size(images, align_mode)
        
        print(f"[ImageAccumulator] ğŸ¯ å¯¹é½æ¨¡å¼: {align_mode}, ç›®æ ‡å°ºå¯¸: {target_width}x{target_height}")
        
        # å¯¹é½æ‰€æœ‰å›¾åƒå¹¶ç”Ÿæˆé®ç½©
        aligned_images = []
        aligned_masks = []
        
        for i, img in enumerate(images):
            aligned_img, mask = self._align_image_with_mask(img, target_height, target_width, pad_color, generate_mask=True)
            aligned_images.append(aligned_img)
            aligned_masks.append(mask)
        
        # åˆå¹¶ä¸ºbatch
        batch_images = torch.cat(aligned_images, dim=0)
        batch_masks = torch.cat(aligned_masks, dim=0)
        
        print(f"[ImageAccumulator] âœ… æ‰¹æ¬¡è¾“å‡ºå®Œæˆ: images={batch_images.shape}, masks={batch_masks.shape}")
        
        return batch_images, batch_masks
    
    def _get_target_size(self, images: List[torch.Tensor], align_mode: str) -> Tuple[int, int]:
        """
        è·å–ç›®æ ‡å¯¹é½å°ºå¯¸
        
        Args:
            images: å›¾åƒåˆ—è¡¨
            align_mode: å¯¹é½æ¨¡å¼
            
        Returns:
            (target_height, target_width)
        """
        if align_mode == "first":
            # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾åƒçš„å°ºå¯¸
            return images[0].shape[1], images[0].shape[2]
        
        elif align_mode == "largest":
            # ä½¿ç”¨æœ€å¤§å°ºå¯¸
            max_h = max(img.shape[1] for img in images)
            max_w = max(img.shape[2] for img in images)
            return max_h, max_w
        
        elif align_mode == "smallest":
            # ä½¿ç”¨æœ€å°å°ºå¯¸ï¼ˆä¼šè£å‰ªï¼‰
            min_h = min(img.shape[1] for img in images)
            min_w = min(img.shape[2] for img in images)
            return min_h, min_w
        
        else:
            # é»˜è®¤ä½¿ç”¨æœ€å¤§å°ºå¯¸
            max_h = max(img.shape[1] for img in images)
            max_w = max(img.shape[2] for img in images)
            return max_h, max_w
    
    def _align_image_with_mask(self, image: torch.Tensor, target_h: int, target_w: int, pad_color: str, generate_mask: bool) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å¯¹é½å›¾åƒåˆ°ç›®æ ‡å°ºå¯¸å¹¶ç”Ÿæˆé®ç½©ï¼ˆå±…ä¸­å¡«å……æˆ–è£å‰ªï¼‰
        
        Args:
            image: å›¾åƒå¼ é‡ [1, H, W, C]
            target_h: ç›®æ ‡é«˜åº¦
            target_w: ç›®æ ‡å®½åº¦
            pad_color: å¡«å……é¢œè‰²ï¼ˆåå…­è¿›åˆ¶ï¼Œå¦‚ #000000ï¼‰
            generate_mask: æ˜¯å¦ç”Ÿæˆé®ç½©
            
        Returns:
            (å¯¹é½åçš„å›¾åƒ [1, H, W, C], é®ç½© [1, H, W])
        """
        current_h, current_w = image.shape[1], image.shape[2]
        
        # å¦‚æœå°ºå¯¸å·²ç»åŒ¹é…ï¼Œç›´æ¥è¿”å›
        if current_h == target_h and current_w == target_w:
            # å…¨ç™½é®ç½©ï¼ˆå…¨éƒ¨æ˜¯åŸå§‹å›¾åƒï¼‰
            mask = torch.ones((1, target_h, target_w), dtype=torch.float32)
            return image, mask
        
        # è®¡ç®—å¡«å……æˆ–è£å‰ªé‡
        pad_top = max(0, (target_h - current_h) // 2)
        pad_bottom = max(0, target_h - current_h - pad_top)
        pad_left = max(0, (target_w - current_w) // 2)
        pad_right = max(0, target_w - current_w - pad_left)
        
        # è§£æåå…­è¿›åˆ¶é¢œè‰²å€¼
        color_value = self._parse_hex_color(pad_color)
        
        # å¦‚æœéœ€è¦å¡«å……
        if pad_top > 0 or pad_bottom > 0 or pad_left > 0 or pad_right > 0:
            # å¡«å……å›¾åƒ
            padded = torch.nn.functional.pad(
                image, 
                (0, 0, pad_left, pad_right, pad_top, pad_bottom),
                mode='constant',
                value=color_value
            )
            
            # ç”Ÿæˆé®ç½©ï¼šåŸå§‹å›¾åƒåŒºåŸŸä¸ºç™½è‰²(1.0)ï¼Œå¡«å……åŒºåŸŸä¸ºé»‘è‰²(0.0)
            mask = torch.zeros((1, target_h, target_w), dtype=torch.float32)
            mask[0, pad_top:pad_top+current_h, pad_left:pad_left+current_w] = 1.0
            
            return padded, mask
        
        # å¦‚æœéœ€è¦è£å‰ª
        else:
            crop_top = (current_h - target_h) // 2
            crop_left = (current_w - target_w) // 2
            cropped = image[:, crop_top:crop_top+target_h, crop_left:crop_left+target_w, :]
            
            # è£å‰ªåçš„é®ç½©å…¨ç™½ï¼ˆå…¨éƒ¨æ˜¯åŸå§‹å›¾åƒï¼‰
            mask = torch.ones((1, target_h, target_w), dtype=torch.float32)
            
            return cropped, mask
    
    def _parse_hex_color(self, hex_color: str) -> float:
        """
        è§£æåå…­è¿›åˆ¶é¢œè‰²ä¸ºç°åº¦å€¼
        
        Args:
            hex_color: åå…­è¿›åˆ¶é¢œè‰²ï¼ˆå¦‚ #000000, #FFFFFFï¼‰
            
        Returns:
            ç°åº¦å€¼ 0.0-1.0
        """
        try:
            # ç§»é™¤ # å·
            hex_color = hex_color.lstrip('#')
            
            # å¤„ç†ç®€å†™å½¢å¼ (å¦‚ #000 -> #000000)
            if len(hex_color) == 3:
                hex_color = ''.join([c*2 for c in hex_color])
            
            # è§£æ RGB
            r = int(hex_color[0:2], 16) / 255.0
            g = int(hex_color[2:4], 16) / 255.0
            b = int(hex_color[4:6], 16) / 255.0
            
            # è½¬æ¢ä¸ºç°åº¦ï¼ˆä½¿ç”¨æ ‡å‡†å…¬å¼ï¼‰
            gray = 0.299 * r + 0.587 * g + 0.114 * b
            
            return gray
            
        except Exception as e:
            print(f"[ImageAccumulator] âš ï¸  è§£æé¢œè‰²å¤±è´¥ '{hex_color}': {e}ï¼Œä½¿ç”¨é»‘è‰²")
            return 0.0  # é»˜è®¤é»‘è‰²
    
    def _load_image_from_file(self, filepath: str) -> torch.Tensor:
        """
        ä»æ–‡ä»¶åŠ è½½å›¾åƒä¸ºå¼ é‡
        
        Args:
            filepath: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒå¼ é‡ [1, H, W, C]
        """
        img = Image.open(filepath)
        img = img.convert("RGB")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        img_np = np.array(img).astype(np.float32) / 255.0
        
        # è½¬æ¢ä¸ºtorchå¼ é‡
        image = torch.from_numpy(img_np).unsqueeze(0)  # [1, H, W, C]
        
        return image
    
    def _clear_gallery(self):
        """æ¸…ç©ºå›¾åƒåº“ï¼ˆåˆ é™¤æ‰€æœ‰æ–‡ä»¶å’Œå…ƒæ•°æ®ï¼‰"""
        print(f"[ImageAccumulator] æ¸…ç©ºå›¾åƒåº“ï¼Œå…± {len(self.image_metadata)} å¼ å›¾åƒ")
        
        # åˆ é™¤æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
        for metadata in self.image_metadata:
            if os.path.exists(metadata["temp_path"]):
                try:
                    os.remove(metadata["temp_path"])
                except Exception as e:
                    print(f"[ImageAccumulator] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ¸…ç©ºå…ƒæ•°æ®
        self.image_metadata.clear()
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """æ¯æ¬¡éƒ½æ‰§è¡Œï¼ˆå› ä¸ºéœ€è¦ç´¯ç§¯å›¾åƒï¼‰"""
        return float("nan")  # æ€»æ˜¯æ ‡è®°ä¸ºå·²æ”¹å˜


# æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "YCImageAccumulator": YCImageAccumulator,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "YCImageAccumulator": "YC Image Accumulator",
}